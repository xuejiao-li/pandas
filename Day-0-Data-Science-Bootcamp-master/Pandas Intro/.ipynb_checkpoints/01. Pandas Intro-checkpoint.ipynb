{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pandas Intro\n",
    "\n",
    "### Objectives\n",
    "After this lesson you should be able to...\n",
    "\n",
    "+ Get help by knowing your object, reading documentation and using inline commands\n",
    "+ Know why Pandas is more suitable for data analysis than Python lists\n",
    "+ Know the anatomy of a DataFrame and a Series\n",
    "+ Identify a Series as a single dimensional data structure with an **index** and **values**\n",
    "+ Identify a DataFrame as a two dimensional data structure with an **index**, **columns**, and **values**\n",
    "+ Know the difference between an **index** and **values**\n",
    "+ Know all the possible column data types\n",
    "+ Know that each value in a column must be of the same data type\n",
    "+ Know the representations of missing values and which ones are used for each data type\n",
    "+ Know how to get metadata with **`info`**, **`shape`**, and **`size`**\n",
    "\n",
    "### Prepare for this lesson by...\n",
    "\n",
    "+ Read the [Package Overview](http://pandas.pydata.org/pandas-docs/stable/overview.html)\n",
    "+ Read [Intro to Data Structures](http://pandas.pydata.org/pandas-docs/stable/dsintro.html) - **just the Series and DataFrame sections**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ....\n",
    "![][1]\n",
    "\n",
    "\n",
    "### What is Pandas?\n",
    "Pandas is one of the better open source data exploration libraries currently available. It gives the user power to explore, manipulate, query, aggregate, and visualize **tabular** data. Tabular meaning data that is two dimensional with rows and columns, i.e. a table.\n",
    "\n",
    "### Why Pandas and not xyz?\n",
    "In this current age of data explosion, there are now many dozens of other tools that can do many, if not more, than what the Pandas library can do. However, there are many aspects of Pandas that set it apart and it continues to have one of the fastest growing user bases.\n",
    "\n",
    "* It's a Python library, which makes it easy to read, easy to develop, and easily integrates with other popular data science libraries like numpy, scikit-learn, statsmodels, matplotlib and seaborn.\n",
    "* It is nearly self-contained in that lots of functionality is built into one package. This contrasts with R, where many packages are needed to obtain the same functionality.\n",
    "* The community is amazing. Looking at Stack Overflow, for example, there are [many ten's of thousands of][2] Pandas questions. SAS, a multi-billion dollar revenue analytics software maker has only a fraction of the questions. This is one huge benefit of open source in general. If you need help, you are nearly guaranteed to find it very quickly. After a while most of your questions will be answered in the top few search engine results.\n",
    "\n",
    "### Why is it named after an east Asian bear?\n",
    "\n",
    "Pandas was built by Wes McKinney beginning in 2008 at a hedge fund named AQR. Finance speak is to call tabular data 'panel data' which smashed together becomes Pandas. If you are really interested in the history, you can hear it from the creator [himself][3].\n",
    "\n",
    "### Python already has data structures to handle data, why do we need another one?\n",
    "Even though Python itself is a high level language, its primary built-in data structures - lists and dicts - do not easily lend themselves to tabular data in ways that humans can operate on them. Just summing items in a list can be quite slow.\n",
    "\n",
    "### NumPy\n",
    "NumPy ('numerical Python') is the most popular third-party Python library for scientific computing and forms the foundation for dozens of others, including Pandas. NumPy's primary data structure is an n-dimensional array which is much more powerful than a Python list and with much better performance.\n",
    "\n",
    "### Pandas is built directly on NumPy\n",
    "All of the data in Pandas is stored in NumPy arrays. That said, it isn't necessary to know much about NumPy when learning Pandas. You can think of Pandas as a higher-level, easier to use interface to doing data analysis than NumPy. It is a good idea to eventually learn NumPy, but for most tasks, Pandas will be the right tool.\n",
    "\n",
    "### NumPy vs built-in list performance difference\n",
    "Let's see the performance difference between summing a NumPy array with one million elements vs a built-in list with the same number of elements.\n",
    "\n",
    "[1]: images/pandas.png\n",
    "[2]: http://stackoverflow.com/questions/tagged/pandas\n",
    "[3]: https://www.youtube.com/watch?v=kHdkFyGCxiY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of 1 million integers\n",
    "n = 1000000\n",
    "my_list = list(range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Code Execution with %timeit\n",
    "**`%timeit`** is a magic command that times the execution of a the first statement in a particular cell. The option **`-r`** controls the number of runs and **`-n`** controls the number of iterations with each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 3 -n 5 sum(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to NumPy array\n",
    "We will import NumPy, create an array with the same elements with the **`arange`** function, and time its summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array with arange function.\n",
    "array = np.arange(n)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 3 -n 5 array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance difference\n",
    "Using the built-in **`sum`** function with a list took approximately 10 times longer than using NumPy's array and this was just a simple sum of a list of numbers. This difference increases with the complexity of the operation performed on the data.\n",
    "\n",
    "### Why is NumPy so fast?\n",
    "NumPy array operations are executed in pre-compiled C code which makes for much faster execution times. A Python list, in contrast, must be iterated through at run-time, can take any number of different types so is not optimized for large numerical computations. \n",
    "\n",
    "### Why not NumPy?\n",
    "Though NumPy is fast and can handle most of our data needs, it is still relatively low-level. Pandas allows easier access to rows and columns, powerful statistical functionality, heterogeneous data, enhanced merging and grouping, and many more data manipulation abilities. \n",
    "\n",
    "More info on NumPy can be found [in the official documentation][2]. We will be using some NumPy directly in this course.\n",
    "\n",
    "### More on magic commands\n",
    "iPython comes with handy dandy magic commands that give you some great extra functionality. The one I use the most is **`timeit`** which times the length of the operation. Magic commands are not Python syntax and only within iPython or Jupyter notebooks. \n",
    "\n",
    "Precede the command by `%` for a single line magic and `%%` for entire cell magic. See the [documentation][1] for a huge list of more magic commands.\n",
    "\n",
    "There is even a magic command to list all the magic commands - see below:\n",
    "\n",
    "[1]: http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "[2]: https://docs.scipy.org/doc/numpy/user/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all the iPython magic commands\n",
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas uses tabular (table) data\n",
    "\n",
    "There are numerous formats for data such as XML, JSON, raw bytes, and many others. But, for our purposes, we will only be examining what everyone thinks of when the they think of data - a table. Pandas is built just for analyzing this tabular, rectangular, very deceptively normal concept of data. \n",
    "\n",
    "There are two primary Pandas objects that account for nearly everything we will be covering. \n",
    "\n",
    "### Series and the DataFrame\n",
    "\n",
    "The **Series** is a single dimension of data. Think of a one dimensional array.\n",
    "\n",
    "The **DataFrame** is our two-dimensional data structure that looks like any other table of data you have seen with rows and columns.\n",
    "\n",
    "# Import Pandas and read in data\n",
    "By convention pandas is imported and aliased as **`pd`**. We will read in the **`bikes`** dataset with the **`read_csv`** function. Its first parameter is the location of the file relative to the current directory. All the data for this class is stored in the **`data`** directory one level above where this notebook is located. \n",
    "\n",
    "The two dots in the path passed to **`read_csv`** are interpreted as the directory immediately above the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('../data/bikes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display DataFrame in Jupyter Notebook\n",
    "We assigned the output from the **`read_csv`** function to the **`bikes`** variable which is now our DataFrame. Display it by putting the variable name as the last line in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default output\n",
    "Pandas defaults to outputting 60 rows and 20 columns. These display options (and many others) can be changed and will be shown later.\n",
    "\n",
    "## Our first methods, `head`, and `tail`\n",
    "A very useful and simple method is **`head`**, which by default will return the first 5 rows of the DataFrame. This avoids the long default output and something I highly recommend. The **`tail`** method returns the last 5 rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First and Last `n` rows\n",
    "Both the **`head`** and **`tail`** methods take a single parameter **`n`** which control the number of rows to return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a DataFrame - Columns, Index, and Data\n",
    "The DataFrame is composed of three separate components that you must know. The **Columns**, the **Index**, and the **Data**. These terms will be used throughout the course and understanding them is vital to your ability to use Pandas.\n",
    "\n",
    "Take a look at the following graphic of our bikes DataFrame stylized to put emphasis on each component.\n",
    "\n",
    "![][1]\n",
    "\n",
    "* The **index** labels the rows\n",
    "* The **columns** label the columns\n",
    "* The **index** is also referred to as the **row names/labels**\n",
    "* The **columns** are also referred to as the **column names/lables** or the **column index**\n",
    "* An individual element of the index is referred to as an **index label/name** or **row label/name**\n",
    "* An individual element of the columns is a **column name/label**\n",
    "* The index and the columns are always in **bold font**\n",
    "* Collectively the index and the columns are known as the **axes** (or individually as an **axis**)\n",
    "* Pandas uses integers to refer to each axis. **0** for the index and **1** for the columns. This is borrowed directly from NumPy\n",
    "* The actual **data** is always in normal font\n",
    "* Data is also referred to as the **values**\n",
    "\n",
    "\n",
    "[1]: images/df_components.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What type of object is `bikes`\n",
    "As we said previously **`bikes`** is a DataFrame. Let's verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-qualified name\n",
    "Remember that only the word after the last dot is the class name. The **`bikes`** variable has type **`DataFrame`**. Python always returns the location and module name of where the class was defined. \n",
    "\n",
    "### Location and module name?\n",
    "The fully-qualified name holds the location in your computer where the class is defined. In this example, **`pandas`** is a directory that contains another directory **`core`** which contains a file **`frame.py`** which defines the **`DataFrame`** class.\n",
    "\n",
    "### Package, sub-package, and module\n",
    "The top level directory of other files and directories containing Python files is technically called a **package**. In this example **`pandas`** is the package. All directories within the package are called **sub-packages** such as **`core`**. All Python files (those ending in .py) are called **modules**.\n",
    "\n",
    "### Where are the packages located?\n",
    "Third-party packages are installed in the **`site-packages`** directory which itself is set up during Python installation. We can get the actual location with the help of the built-in **`site`** module's **`getsitepackages`** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site.getsitepackages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a single column from a DataFrame - a Series\n",
    "To select a single column from a DataFrame, pass the name of one of the columns to the indexing operator, **`[]`**. The returned object will be a Pandas Series. Let's choose the column name **`tripduration`**, assign it to a variable, and output it to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration = bikes['tripduration']\n",
    "trip_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `head` and `tail` methods work the same with a Series\n",
    "Use the **`head`** and **`tail`** methods to condense the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a Series - Index and Data\n",
    "A Series is simpler than a DataFrame with just a single dimension of data. It has two components - the **index** and the **data**. It is essentially a one-column DataFrame. Let's take a look at a stylized Series graphic.\n",
    "\n",
    "![](images/series_components.png)\n",
    "\n",
    "The definition for the index and data components are the same as they are for a DataFrame.\n",
    "\n",
    "### Output of Series vs DataFrame\n",
    "Notice that there is no nice HTML styling for the Series. It's just plain text. Also, below each Series will be some metadata on it - the **name**, **length**, and **dtype**. \n",
    "\n",
    "* The **name** is not important right now, but if the Series is formed from a column of a DataFrame it will be set to that column name.\n",
    "* The **length** is simply the number of values in the Series\n",
    "* The **dtype** is the data type of the Series. Each column of data must be of only one particular data type. These will be covered in depth later.\n",
    "\n",
    "It's important to note that this metadata is NOT part of the Series itself and just some extra info Pandas outputs for your information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data  Types \n",
    "Each column of data in Pandas DataFrame has a **data type**. This is a very similar concept to types in Python. Just like every object has a type, every column has a data type. Every value in each column must be of the same data type.\n",
    "\n",
    "## Most Common Data Types\n",
    "The following are the most common data types that appear frequently in DataFrames. \n",
    "\n",
    "* **Boolean**\n",
    "* **Integer**\n",
    "* **Float**\n",
    "* **Object** (mainly strings)\n",
    "* **DateTime** (a specific moment in time)\n",
    "\n",
    "### Other Data Types\n",
    "There are three other data types that are less common. We will cover them when necessary.\n",
    "\n",
    "* **Category**\n",
    "* **TimeDelta** (a specific amount of time)\n",
    "* **Period** (a specific time period)\n",
    "\n",
    "### More on the primary data types\n",
    "\n",
    "#### Boolean\n",
    "Boolean columns contain only two values: **`True`** and **`False`**\n",
    "\n",
    "#### Integer\n",
    "Whole numbers without a decimal\n",
    "\n",
    "#### Float\n",
    "Numbers with decimals\n",
    "\n",
    "#### Object\n",
    "This object data type is a bit confusing. It means that each value in the column can be any valid Python object. But, nearly all of the time, object data type columns contain **strings**. They can contain any other Python object such as integers, floats, or even complex types such as lists or dictionaries.\n",
    "\n",
    "When you see **object** as a data type you should think of **string**.\n",
    "\n",
    "#### DateTime\n",
    "A DateTime is a specific moment in time with both a **date** (month, year, day) and a **time** (hour, minute, second, fraction of a second). All DateTimes in Pandas have nanosecond precision - 1 billionth of a second.\n",
    "\n",
    "# Missing Values\n",
    "Missing value representation is actually a fairly complex issue. If you are curious you can read a [small manifesto][1] on it from the NumPy developers.\n",
    "\n",
    "## Missing Value Representation, `NaN`,  `None`, and `NaT`\n",
    "Pandas representats missing values differently based on the data type of the column.\n",
    "\n",
    "### Where do these missing values come from?\n",
    "* **`NaN`** stands for **not a number** and is technically a floating point value\n",
    "* **`None`** is the literal Python object **`None`**. This will only be found in **object** columns\n",
    "* **`NaT`** stands for not a time and is used for missing values in DateTime, TimeDelta, and Period columns\n",
    "\n",
    "### Missing values for each data type\n",
    "**Booleans and integers** do not have any representation for missing values. This is unfortunate, but a current limitation. If you have booleans or integers in your data that have missing values they will be coerced to floats.\n",
    "\n",
    "**Floats** use only **`NaN`** as the missing value.  \n",
    "\n",
    "**Object** can be any valid Python object so technically you may see **`NaN`**, **`None`**, or **`NaT`** but primarily you will see **`None`** used in object columns.\n",
    "\n",
    "**Datetime**, **TimeDelta**, **Period** will only use **`NaT`** as the missing value.\n",
    "\n",
    "# Finding the data types of each column\n",
    "The **`dtypes`** DataFrame method returns the data type of each column. Let's get the data types of our **`bikes`** DataFrame.\n",
    "\n",
    "[1]: https://docs.scipy.org/doc/numpy/neps/missing-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think string whenever you see object\n",
    "Pandas does not have a string data type like most databases but when you see **object** you should assume that the column consists entirely of strings.\n",
    "\n",
    "# Why are `starttime` and `stoptime` object data types?\n",
    "If you look at the output of the **`bikes`** DataFrame, it's apparent that both the **`starttime`** and **`stoptime`** columns are DateTimes but our last output from above is stating that they are objects.\n",
    "\n",
    "When reading in a text file like we did with **`bikes.csv`** it's impossible for Pandas to know the data type of each column so it makes assumptions as it's reading it in. We can force Pandas to read these columns as DateTimes with the **`parse_dates`** parameter of the **`read_csv`** function. We must pass it a list of the columns we would like to make datetimes.\n",
    "\n",
    "Let's re-read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv', parse_dates=['starttime', 'stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are all those 64's at the end of the data types?\n",
    "Integers, floats, DateTimes and TimeDeltas all use a particular amount of memory for each of their values. The memory is measured in **`bits`**. By default Pandas uses 64 bits to represent integers, floats, DateTimes, and TimeDeltas. It is possible to use a different number of bits for integers and floats. \n",
    "\n",
    "Integers can be either 8, 16, 32, or 64 bits while floats can be 16, 32, 64, or 128. For instance, a 128-bit float column will show up as **`float128`**. \n",
    "\n",
    "Technically a **`float128`** is a different data type than a **`float64`** but generally you will never have to worry about such a distinction as the operations between different float columns will be the same. It's also very rare to see anything other than 64 bit integer or floats since that is the default and you would need to manually change their size to get a different type.\n",
    "\n",
    "**Booleans** are stored as a 8-bits, also known as a single **byte**. DateTimes and TimeDeltas are always stored as 64-bits. **Objects** can store any Python object, so there is no set amount of memory for each of their values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting more Metadata\n",
    "Metadata is data on the data. The data type of each column is an example of **metadata**. The number of rows and columns is another piece of metadata. We find this with the **`shape`** attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of elements with `size` attribute\n",
    "The **`size`** attribute returns the total number of elements (the number of columns multiplied by the number of rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Types plus more with the `info` method\n",
    "The **`info`** DataFrame method retuns output similar to **`dtypes`** but also returns the number of non-missing values in each column along with more info such as the \n",
    "* Type of object (always a DataFrame)\n",
    "* The type of index and number of rows\n",
    "* The number of columns\n",
    "* The data types of each column and the number of non-missing (a.k.a non-null)\n",
    "* The frequency count of all data types\n",
    "* The total memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Use the **`bikes`** DataFrame for the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Select the column **`events`**, the type of weather that was recorded and assign it to a variable with the same name. Output the first 10 values of it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is **`events`**?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Select the last 2 rows of the **`bikes`** DataFrame and assign it to the variable **`bikes_last_2`**. What type of object is **`bikes_last_2`**?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is returned from the **`dtypes`** attribute?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is returned from the **`shape`** attribute?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is returned from the **`info`** method?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "<span  style=\"color:green; font-size:16px\">The memory usage from the **`info`** method isn't correct when you have objects in your DataFrame. Read the docstrings from it and get the true memory usage.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore more on your own below\n",
    "Think of your own questions, then ask and answer them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
